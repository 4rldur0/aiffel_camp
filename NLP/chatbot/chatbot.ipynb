{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 \n",
    "\n",
    "https://github.com/songys/Chatbot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>고양이 키우고 싶어</td>\n",
       "      <td>가족들과 상의해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>공시 준비 힘들어</td>\n",
       "      <td>잘 될 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>돈 벌고 싶어</td>\n",
       "      <td>많이 벌수록 좋아요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>로또 번호 알려줘</td>\n",
       "      <td>알면 제가 하죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>마음이 울적해</td>\n",
       "      <td>거리를 걸어보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>착해서 잘해주는 건지 좋아하는 건지</td>\n",
       "      <td>헷갈린다고 말해보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>첫 눈에 반하는게 가능해?</td>\n",
       "      <td>당연히 가능하죠.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658</th>\n",
       "      <td>첫사랑 생각나</td>\n",
       "      <td>지금의 사랑에 충실하세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>커플여행이 나을까 그냥 우리끼리 갈까?</td>\n",
       "      <td>저는 둘이 가는 게 좋아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Q                A  label\n",
       "196               고양이 키우고 싶어     가족들과 상의해보세요.      0\n",
       "235                공시 준비 힘들어         잘 될 거예요.      0\n",
       "1294                 돈 벌고 싶어      많이 벌수록 좋아요.      0\n",
       "1445               로또 번호 알려줘        알면 제가 하죠.      0\n",
       "1481                 마음이 울적해       거리를 걸어보세요.      0\n",
       "...                      ...              ...    ...\n",
       "11642    착해서 잘해주는 건지 좋아하는 건지     헷갈린다고 말해보세요.      2\n",
       "11649         첫 눈에 반하는게 가능해?        당연히 가능하죠.      2\n",
       "11658                첫사랑 생각나   지금의 사랑에 충실하세요.      2\n",
       "11732  커플여행이 나을까 그냥 우리끼리 갈까?  저는 둘이 가는 게 좋아요.      2\n",
       "11819         훔쳐보는 것도 눈치 보임.    훔쳐보는 거 티나나봐요.      2\n",
       "\n",
       "[161 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 질문 확인\n",
    "df[df.duplicated(\"Q\") == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>고양이 키우고 싶어</td>\n",
       "      <td>자신을 먼저 키우세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>고양이 키우고 싶어</td>\n",
       "      <td>가족들과 상의해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q             A  label\n",
       "195  고양이 키우고 싶어  자신을 먼저 키우세요.      0\n",
       "196  고양이 키우고 싶어  가족들과 상의해보세요.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Q\"] == \"고양이 키우고 싶어\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    import re\n",
    "\n",
    "    sentence = sentence.lower()  # 소문자화\n",
    "    sentence = re.sub(r\"[^가-힣1-9a-zA-Z?.!,]+\", \" \", sentence)  # 기타 문자 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(df, length, labels):\n",
    "    from konlpy.tag import Mecab\n",
    "\n",
    "    tokenizer = Mecab(dicpath=r\"C:\\mecab\\share\\mecab-ko-dic\")\n",
    "    df_copy = df.copy()\n",
    "    for l in labels:\n",
    "        df_copy[l] = df_copy[l].apply(lambda x: preprocessing(x))\n",
    "        df_copy[l] = df_copy[l].apply(lambda x: tokenizer.morphs(x))\n",
    "        df_copy = df_copy[df_copy[l].apply(len) <= length]\n",
    "    df_copy = df_copy.drop_duplicates(labels[0])\n",
    "\n",
    "    return df_copy, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean, tokenizer = build_corpus(df, 20, df.columns[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 길이 제한으로 사라진 데이터 수 : 328, 2.774253573543094%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"데이터 길이 제한으로 사라진 데이터 수 : {df.shape[0]-df_clean.shape[0]}, {(df.shape[0]-df_clean.shape[0])/df.shape[0]*100}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 추가\n",
    "df_clean[\"A\"] = df_clean[\"A\"].apply(lambda x: [\"<start>\"] + x + [\"<end>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df, NUM_WORDS):\n",
    "    vectorizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS, filters=\"\")\n",
    "    corpus = []\n",
    "    for _, sentence in df.iterrows():\n",
    "        corpus.extend(sentence[df.columns[0]])\n",
    "        corpus.extend(sentence[df.columns[1]])\n",
    "    vectorizer.fit_on_texts(corpus)\n",
    "\n",
    "    temp_df = df.copy()\n",
    "    temp_df[\"Q\"] = vectorizer.texts_to_sequences(df[\"Q\"])\n",
    "    temp_df[\"A\"] = vectorizer.texts_to_sequences(df[\"A\"])\n",
    "    max_len = max(temp_df[\"Q\"].apply(len).max(), temp_df[\"A\"].apply(len).max())\n",
    "\n",
    "    Q = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        temp_df[\"Q\"], maxlen=max_len, padding=\"post\"\n",
    "    )\n",
    "    A = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        temp_df[\"A\"], maxlen=max_len, padding=\"post\"\n",
    "    )\n",
    "\n",
    "    return Q, A, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, dec_train, vectorizer = vectorize(df_clean, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = enc_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6767"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 단어 개수\n",
    "len(vectorizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델\n",
    "\n",
    "트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"chatbot.ipynb\"))\n",
    "model_dir = os.path.abspath(os.path.join(current_dir, \"../../model\"))\n",
    "sys.path.append(model_dir)\n",
    "\n",
    "import transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'transformer' from 'c:\\\\Users\\\\zzoon\\\\projects\\\\aiffel_camp\\\\model\\\\transformer.py'>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = [\n",
    "    \"지루하다, 놀러가고 싶어.\",\n",
    "    \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "    \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "    \"집에 있는다는 소리야.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vectorizer.num_words:\n",
    "    VOCAB_SZIE = vectorizer.num_words\n",
    "else:\n",
    "    VOCAB_SZIE = len(vectorizer.word_index)\n",
    "\n",
    "model = transformer.Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=256,\n",
    "    n_heads=8,\n",
    "    d_ff=512,\n",
    "    src_vocab_size=VOCAB_SZIE,\n",
    "    tgt_vocab_size=VOCAB_SZIE,\n",
    "    pos_len=enc_train.shape[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 180/180 [00:09<00:00, 19.27it/s, Loss 2.8085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 마음 이 있 었 나 봐요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 마음 이 필요 한 것 같 아요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 사랑 에 는 게 좋 겠 네요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 마음 이 좀 더 좋 겠 네요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2: 100%|██████████| 180/180 [00:04<00:00, 44.44it/s, Loss 2.7389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 아 하 는 게 좋 겠 죠 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 마음 이 필요 한 것 같 아요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 사랑 은 선 에 대한 사랑 이 에요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 서로 에게 좋 아 하 는 게 좋 겠 어요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3: 100%|██████████| 180/180 [00:03<00:00, 46.04it/s, Loss 2.5817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 아 하 는 게 좋 겠 죠 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 좋 아 하 는 게 좋 겠 죠 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 사랑 은 선 에 대한 예의 가 없 을 거 예요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 서로 에게 좋 겠 어요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4: 100%|██████████| 180/180 [00:03<00:00, 46.52it/s, Loss 2.3376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 아 하 는 게 좋 겠 죠 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 좋 아 하 는 게 좋 을 거 예요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 좋 은 소식 이 었 을 거 예요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 서로 에게 좋 은 소식 이 네요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5: 100%|██████████| 180/180 [00:03<00:00, 48.19it/s, Loss 2.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 충분히 그럴 수 있 을 거 예요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 마음 이 따뜻 한 것 같 아요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 뭐 하 겠 어요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 축하 합니다 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6: 100%|██████████| 180/180 [00:04<00:00, 44.43it/s, Loss 1.7357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 아 하 는 게 좋 겠 지만 마음 이 좋 겠 어요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 소식 만 해도 정리 해도 돼요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 다시 어느 정도 모습 이 되 었 길 바랍니다 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 축하 드려요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7: 100%|██████████| 180/180 [00:04<00:00, 43.47it/s, Loss 1.5855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 마음 이 우연 을 수 있 는 게 좋 겠 죠 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 술 이란 만 해도 돼요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 좋 아 하 는 게 뭔지 해 보 세요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 축하 드려요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8: 100%|██████████| 180/180 [00:04<00:00, 40.79it/s, Loss 1.3726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 아 질 거 예요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 오늘 술 만 의 사정 이 있 나 봐요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 부모 님 이나 봐요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 페북 을 가지 고 다시 기다릴 수 있 을 거 예요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9: 100%|██████████| 180/180 [00:04<00:00, 41.80it/s, Loss 1.1910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 아 하 는지 놀 보 세요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 나 의 나 를 위해 좋 은 소식 에 나 봅니다 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 만날 수 있 을 거 예요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 상황 이 든 대해 다르 죠 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 180/180 [00:03<00:00, 45.25it/s, Loss 1.0400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 아 하 는 마음 을 때 가 있 기 도 할 거 예요\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 짝사랑 하 나 봐요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 만날 수 없 는 부분 이 었 을 수 도 있 죠 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 같이 연락 두 는 것 이 라도 하 지 않 는 거\n"
     ]
    }
   ],
   "source": [
    "transformer.train(\n",
    "    model,\n",
    "    dataset,\n",
    "    EPOCH=10,\n",
    "    enc_tokenizer=vectorizer,\n",
    "    dec_tokenizer=vectorizer,\n",
    "    example_sentence=example_sentence,\n",
    "    type=\"mecab\",\n",
    "    plot_attention=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Sample: 100\n",
      "Total Score: 0.3341864783791095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(transformer)\n",
    "\n",
    "transformer.eval_bleu(\n",
    "    model,\n",
    "    df[\"Q\"][:100],\n",
    "    df[\"A\"][:100],\n",
    "    vectorizer,\n",
    "    vectorizer,\n",
    "    \"mecab\",\n",
    "    max_len,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
