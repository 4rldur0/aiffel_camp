{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b914d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4650c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/custom_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa34bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['협박 대화', '기타 괴롭힘 대화', '갈취 대화', '직장 내 괴롭힘 대화', '일반 대화'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label = data['class'].unique()\n",
    "class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0245a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리\n",
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = sentence.replace(\"\\n\", \"\")         # 구분자\n",
    "    sentence = sentence.replace(\"\\r\", \"\")         # 구분자\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z,가-힣,0-9, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣0-9\\.\\?\\!,]\",\" \",sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba92349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['conversation'].apply(preprocess_sentence)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fa9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba92ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = list(np.stack(X.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101b2c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해 ? 진짜 죽여버리고 싶게 . 정말 잘못했습니다 . 너가 선택해 . 너가 죽을래 네 가족을 죽여줄까 . 죄송합니다 . 정말 잘못했습니다 . 너에게는 선택권이 없어 . 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야 . 선택 못하겠습니다 . 한번만 도와주세요 . 그냥 다 죽여버려야겠군 . 이의 없지 ? 제발 도와주세요 .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16aa94",
   "metadata": {},
   "source": [
    "## KoBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8979d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/SKTBrain/KoBERT/tree/master/kobert_hf\n",
    "\n",
    "# ! pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c36035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb3b5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenizer.encode(X_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585db2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게. 정말 잘못했습니다. 너가 선택해. 너가 죽을래 네 가족을 죽여줄까. 죄송합니다. 정말 잘못했습니다. 너에게는 선택권이 없어. 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야. 선택 못하겠습니다. 한번만 도와주세요. 그냥 다 죽여버려야겠군. 이의 없지? 제발 도와주세요.[SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0987649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  240.11326732673268\n",
      "문장길이 최대 :  906\n",
      "문장길이 표준편차 :  98.91159089852438\n",
      "pad_sequences maxlen :  339\n",
      "전체 문장의 89.72277227722772%가 maxlen 설정값 이내에 포함. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_list)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 문장길이 평균, 최대, 표준편차\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 최대 길이를 (평균 + 2.5*표준편차)\n",
    "max_tokens = np.mean(num_tokens) + 1 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {100 * np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebeb0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(X_list,return_tensors='tf', \n",
    "                   padding=True, truncation=True,max_length=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc27cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.multiply(inputs.input_ids,inputs.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e40252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 4299, 1457, ...,    0,    0,    0],\n",
       "       [   2, 1315, 5872, ...,    0,    0,    0],\n",
       "       [   2, 1457, 1763, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   2, 3121, 5439, ...,    0,    0,    0],\n",
       "       [   2, 4953, 4924, ...,    0,    0,    0],\n",
       "       [   2, 2287, 5330, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847858a2",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ca30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17f563",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a05597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()   # 부모 클래스 상속 초기화, 필수는 아님 \n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            # tf.newaxis : 차원 추가, [:, tf.newaxis]은 열벡터로 변환 \n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],  \n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        # 차원 추가 (1, ...)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'pos_encoding': self.pos_encoding,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e91bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    # tf.shape(key)[-1] = 워드벡터의 크기 \n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    # 마스크의 1이면 큰값을 빼는 거니까 softmax를 지나면 0에 수렴 \n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0651044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 워드벡터가 헤드수로 나머지 없이 나누어 져야함\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        # input.shape : [batch_size, seq_len, d_model(self.num_head*self.depth)]\n",
    "            # seq_len : 문장길이\n",
    "            # d_model : 임베딩 차원 \n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        #[batch_size, self.num_head, seq_len, self.depth)]\n",
    "        # transpose를 통해 num_heads를 앞으로 불러와 병렬연산 효율성(gpu활용성)을 높임 \n",
    "            # 일반적으로 뒷 차원의 크기가 클 수록 효율적\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query,batch_size)\n",
    "        key = self.split_heads(key,batch_size)\n",
    "        value = self.split_heads(value,batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'num_heads': self.num_heads,\n",
    "            'd_model': self.d_model,\n",
    "            'depth': self.depth,\n",
    "            'query_dense': self.query_dense,\n",
    "            'key_dense': self.key_dense,\n",
    "            'value_dense': self.value_dense,\n",
    "            'dense': self.dense,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eba16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자가 0인 부분을 체크한 벡터를 리턴\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e448ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자가 0인 부분도 마스킹\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    # tf.linalg.band_part: 대각요소를 가져오거나 이를 기준을 다른 것을 제거 \n",
    "        # (텐서, 유지할 아래 대각요소, 유지할 위 대각요소) -1이면 전부 \n",
    "        # 대각요소는 항상 유지 \n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8201ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d5fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 인코더. 인코딩 레이어를 여러개 \n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e8325f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                num_classes,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  \n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    # output_shape:mask[:, tf.newaxis, tf.newaxis, :]를 (1,1,batch_size,sequence_length)로 변경\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), \n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model, \n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.GlobalAveragePooling1D()(enc_outputs)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3539bf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 128)    1421696     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 5)            645         global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 1,422,341\n",
      "Trainable params: 1,422,341\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_label)\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "MAX_LENGTH = X.shape[1]\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 3 # 인코더와 디코더의 층의 개수 \n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입/출력의 고정 차원\n",
    "NUM_HEADS = 4 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 256 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17f2fb",
   "metadata": {},
   "source": [
    "F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "517edde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # 예측값을 0과 1로 반올림\n",
    "    y_pred = tf.round(y_pred)\n",
    "\n",
    "    # True Positives, False Positives, False Negatives 계산\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # Precision, Recall 계산\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    # F1 Score 계산\n",
    "    f1_val = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "811f9934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n"
     ]
    }
   ],
   "source": [
    "# 메모리 문제로 메모리 최적화 \n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# Mixed precision policy 설정\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "# Optimizer 설정 (loss scale 추가)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b52baf00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "epochs=10\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy', f1_score])\n",
    "# history = model.fit(X_train,\n",
    "#                     y_train,\n",
    "#                     epochs=epochs,\n",
    "#                     batch_size=1,\n",
    "#                     validation_data=(X_test, y_test),\n",
    "#                     verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8916870",
   "metadata": {},
   "source": [
    "메모리 문제로 학습한거 불러온건데 val_acc, val_f1은 80정도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c04431aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.save_weights('models/transformer_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e38d98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/transformer_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동행렬\n",
    "y_pred = model.predict(X_test,batch_size=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c41bb169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "# 히트맵 그리기\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db5b815",
   "metadata": {},
   "source": [
    "## test 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/custom_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test['conversation'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe2e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test= list(np.stack(test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbabb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = tokenizer(test,return_tensors='tf', \n",
    "                   padding=True, truncation=True,max_length=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c021b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.multiply(inputs_test.input_ids,inputs_test.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24538464",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c6604",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27210b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "results = []\n",
    "for p in pred:\n",
    "    results.append(np.argmax(p))\n",
    "\n",
    "Counter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e6563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
