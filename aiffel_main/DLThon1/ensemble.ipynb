{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5086ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a89f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f2d5b",
   "metadata": {},
   "source": [
    "### 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5317df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/custom_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f78768",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3,\n",
    "    '일반 대화': 4\n",
    "}\n",
    "\n",
    "data['label'] = data['class'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a253323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = sentence.replace(\"\\n\", \"\")         # 구분자\n",
    "    sentence = sentence.replace(\"\\r\", \"\")         # 구분자\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z,가-힣,0-9, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣0-9\\.\\?\\!,]\",\" \",sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de806d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    half_index = len(text) // 2\n",
    "    return text[:half_index], text[half_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bf0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\n",
    "    'idx': [],\n",
    "    'class': [],\n",
    "    'conversation': [],\n",
    "    'label': []\n",
    "}\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    part1, part2 = split_text(row['conversation'])\n",
    "    new_data['idx'].append(row['idx'])\n",
    "    new_data['class'].append(row['class'])\n",
    "    new_data['conversation'].append(part1)\n",
    "    new_data['label'].append(row['label'])\n",
    "    \n",
    "    new_data['idx'].append(row['idx'])\n",
    "    new_data['class'].append(row['class'])\n",
    "    new_data['conversation'].append(part2)\n",
    "    new_data['label'].append(row['label'])\n",
    "\n",
    "# 새로운 데이터 프레임 생성\n",
    "new_df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a40a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['conversation'] = new_df['conversation'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb120ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepcocessed = new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec360544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  119.79089108910891\n",
      "문장길이 최대 :  463\n",
      "문장길이 표준편차 :  49.48689831810592\n",
      "pad_sequences maxlen :  100\n",
      "전체 문장의 35.663366336633665%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# max len길이를 보기위해\n",
    "total_data_text = list(new_df['conversation'])\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens  = np.mean(num_tokens) + 1 * np.std(num_tokens)\n",
    "max_tokens = 100\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)*100}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89c17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터\n",
    "\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed26815",
   "metadata": {},
   "source": [
    "### 서브워드 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88351f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer_sw = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(new_df['conversation'] , target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2804dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer_sw.vocab_size], [tokenizer_sw.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer_sw.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08982dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = tokenizer_sw.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27933413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs):\n",
    "    outputs = []\n",
    "  \n",
    "    for sentence in inputs:\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence = START_TOKEN + tokenizer_sw.encode(sentence) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence) <= MAX_LENGTH :\n",
    "            outputs.append(sentence)    \n",
    "        \n",
    "    # 최대 길이 으로 모든 데이터셋을 패딩\n",
    "    outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e91624aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_conversations(df):\n",
    "    filtered_conversations = []\n",
    "    indices = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        sentence = row['conversation']\n",
    "        encoded_sentence = START_TOKEN + tokenizer_sw.encode(sentence) + END_TOKEN\n",
    "\n",
    "        if len(encoded_sentence) <= MAX_LENGTH:\n",
    "            filtered_conversations.append(sentence)\n",
    "            indices.append(idx)\n",
    "\n",
    "    return df.loc[indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecde7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = filter_conversations(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5482947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenize_and_filter(new_df['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b285ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(new_df['label']) # label로 주어 올바른 순서로 훈련\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(np.unique(y_train)))\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a29158",
   "metadata": {},
   "source": [
    "### fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73970289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터\n",
    "EPOCH_FT = 100\n",
    "BUCKET_FT = 20000\n",
    "NGRAM_FT = 2\n",
    "DIM_FT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5d31cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(x):\n",
    "    label = x['label']\n",
    "    return f'''__label__{label}    {x['conversation']}'''\n",
    "    \n",
    "\n",
    "add_label_text = data_prepcocessed.apply(add_label, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6ac7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'input_fasttext_conversation.txt'\n",
    "\n",
    "with open(file_path, 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(add_label_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06aa09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b51b51b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  73240\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 1018245 lr:  0.000000 avg.loss:  0.229031 ETA:   0h 0m 0s words/sec/thread: 1031978 lr:  0.765810 avg.loss:  1.110995 ETA:   0h 0m 8s 0.721015 avg.loss:  0.907601 ETA:   0h 0m 8s words/sec/thread: 1026188 lr:  0.319398 avg.loss:  0.343529 ETA:   0h 0m 3s words/sec/thread: 1025537 lr:  0.276811 avg.loss:  0.320775 ETA:   0h 0m 3s 0.301272 ETA:   0h 0m 2s\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "model_ft = fasttext.train_supervised(input=file_path,\n",
    "                                  epoch=EPOCH_FT,\n",
    "                                  bucket = BUCKET_FT,\n",
    "                                  lr = 1,\n",
    "                                  wordNgrams=NGRAM_FT,\n",
    "                                  dim=DIM_FT,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd144d",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d060a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 128)          1040384   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,147,781\n",
      "Trainable params: 1,147,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(MAX_WORDS, 128, input_length=MAX_LENGTH))\n",
    "model_lstm.add(SpatialDropout1D(0.2))\n",
    "model_lstm.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model_lstm.add(Dense(64, activation='relu'))\n",
    "model_lstm.add(Dense(len(np.unique(data['class'])), activation='softmax'))\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97721618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/98 [===>..........................] - ETA: 1:01 - loss: 1.6073 - accuracy: 0.2344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_570/1120123005.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBATCH_SIZE_LSTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model_lstm.fit(X_train, y_train, \n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS_LSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE_LSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS_LSTM = 1\n",
    "BATCH_SIZE_LSTM = 64\n",
    "\n",
    "history = model_lstm.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS_LSTM, \n",
    "                    batch_size=BATCH_SIZE_LSTM, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2b536",
   "metadata": {},
   "source": [
    "### tranformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d58243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d124bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터\n",
    "NUM_LAYERS = 12 # 인코더와 디코더의 층의 개수 \n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입/출력의 고정 차원\n",
    "NUM_HEADS = 4 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 256 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "NUM_CLASSES = len(data['class'].unique())  #레이블 수\n",
    "VOCAB_SIZE = MAX_WORDS #단어사전 크기\n",
    "MAX_LENGTH = X_train.shape[1] # maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79a50e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= transformer.transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d91f841f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 23s 149ms/step - loss: 1.7568 - accuracy: 0.2010 - val_loss: 1.6398 - val_accuracy: 0.1911\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63ce14",
   "metadata": {},
   "source": [
    "## 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f18c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/custom_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac41867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['conversation'] = test['conversation'].apply(preprocess_sentence)\n",
    "tokenizer.fit_on_texts(test['conversation'].values)\n",
    "\n",
    "test_input = tokenizer.texts_to_sequences(test['conversation'].values)\n",
    "test_input = pad_sequences(test_input, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08925446",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ft =  model_ft.predict(list(test['conversation']), k=-1)\n",
    "pred_lstm = model_lstm.predict(test_input)\n",
    "pred_transformer = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49dc72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_ft[1] + pred_lstm + pred_transformer\n",
    "\n",
    "predicted_classes = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec55226",
   "metadata": {},
   "source": [
    "## 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad830996",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"data/new_submission.csv\")\n",
    "sub['class']=predicted_classes\n",
    "# sub.to_csv('data/sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffeb5b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>t_495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>t_496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>t_497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>t_498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>t_499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name  class\n",
       "0       t_000      0\n",
       "1       t_001      0\n",
       "2       t_002      0\n",
       "3       t_003      4\n",
       "4       t_004      0\n",
       "..        ...    ...\n",
       "495     t_495      0\n",
       "496     t_496      0\n",
       "497     t_497      0\n",
       "498     t_498      0\n",
       "499     t_499      0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a213256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
