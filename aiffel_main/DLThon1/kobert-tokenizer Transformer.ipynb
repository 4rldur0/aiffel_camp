{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349b43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498cc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/custom_train_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985801c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['협박 대화', '기타 괴롭힘 대화', '갈취 대화', '직장 내 괴롭힘 대화', '일반 대화'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label = data['class'].unique()\n",
    "class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "050b192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = data['label']\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46558c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = list(np.stack(data['conversation'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d80858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정 과장님 왜 ? 다름이 아니라 저 부모님이 아프신데 간호 할 사람이 저밖에 없어서 휴가를 써야 할 것 같습니다 . 부모님이 아프시면 간병인을 쓰면 되지 않나 . 그래서 자식이 옆에 있어야 조금이라도 도움이 될 것 같아서 그렇습니다 . 안돼 . 내가 누누이 경고했지 집안일을'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list[6436]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48499e0",
   "metadata": {},
   "source": [
    "## KoBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66b2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/SKTBrain/KoBERT/tree/master/kobert_hf\n",
    "\n",
    "# ! pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2143a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c242c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenizer.encode(X_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f85aa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게. 정말 잘못했습니다. 너가 선택해. 너가 죽을래 네 가족을 죽여줄까[SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ffbcf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  143.6829292929293\n",
      "문장길이 최대 :  455\n",
      "문장길이 표준편차 :  70.74681112494424\n",
      "pad_sequences maxlen :  143\n",
      "전체 문장의 60.81818181818182%가 maxlen 설정값 이내에 포함. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_list)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 문장길이 평균, 최대, 표준편차\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 최대 길이를 (평균 + 2.5*표준편차)\n",
    "max_tokens = np.mean(num_tokens) + 0 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {100 * np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59937314",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(X_list,return_tensors='tf', \n",
    "                   padding=True, truncation=True,max_length=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "943a7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.multiply(inputs.input_ids,inputs.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a2feb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 4299, 1457, ...,    0,    0,    0],\n",
       "       [   2,  517,   54, ...,    0,    0,    0],\n",
       "       [   2, 1315, 5872, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   2,  517, 5330, ..., 4955, 6970,    3],\n",
       "       [   2, 3097, 3511, ..., 5770, 1406,    3],\n",
       "       [   2, 1375, 1194, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56a1bb",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284962f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2e5d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1, ..., 3, 3, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ce7437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 3480, 6536, ...,    0,    0,    0],\n",
       "       [   2,  537, 7020, ...,    0,    0,    0],\n",
       "       [   2, 3257, 5330, ...,  905, 7266,    3],\n",
       "       ...,\n",
       "       [   2, 1457, 5702, ..., 1698, 3493,    3],\n",
       "       [   2, 1457, 5025, ...,    0,    0,    0],\n",
       "       [   2, 1316, 7960, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc226889",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c07a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()   # 부모 클래스 상속 초기화, 필수는 아님 \n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            # tf.newaxis : 차원 추가, [:, tf.newaxis]은 열벡터로 변환 \n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],  \n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        # 차원 추가 (1, ...)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'position': self.pos_encoding.shape[1],\n",
    "            'd_model': self.pos_encoding.shape[2],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "708b2b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    # tf.shape(key)[-1] = 워드벡터의 크기 \n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    # 마스크의 1이면 큰값을 빼는 거니까 softmax를 지나면 0에 수렴 \n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a0e774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 워드벡터가 헤드수로 나머지 없이 나누어 져야함\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        # input.shape : [batch_size, seq_len, d_model(self.num_head*self.depth)]\n",
    "            # seq_len : 문장길이\n",
    "            # d_model : 임베딩 차원 \n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        #[batch_size, self.num_head, seq_len, self.depth)]\n",
    "        # transpose를 통해 num_heads를 앞으로 불러와 병렬연산 효율성(gpu활용성)을 높임 \n",
    "            # 일반적으로 뒷 차원의 크기가 클 수록 효율적\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query,batch_size)\n",
    "        key = self.split_heads(key,batch_size)\n",
    "        value = self.split_heads(value,batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'num_heads': self.num_heads,\n",
    "            'd_model': self.d_model,\n",
    "            'depth': self.depth,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483c4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자가 0인 부분을 체크한 벡터를 리턴\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ad52382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자가 0인 부분도 마스킹\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    # tf.linalg.band_part: 대각요소를 가져오거나 이를 기준을 다른 것을 제거 \n",
    "        # (텐서, 유지할 아래 대각요소, 유지할 위 대각요소) -1이면 전부 \n",
    "        # 대각요소는 항상 유지 \n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22091b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f9dc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 인코더. 인코딩 레이어를 여러개 \n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,),name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daff1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                num_classes,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  \n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    # output_shape:mask[:, tf.newaxis, tf.newaxis, :]를 (1,1,batch_size,sequence_length)로 변경\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), \n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model, \n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.GlobalAveragePooling1D()(enc_outputs)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43ea5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install wandb==0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bee31f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7d47aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /aiffel/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key = 'a37365b93b89624b1f639438fcc3d6c5503f21b5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2f31f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "# NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수 \n",
    "# D_MODEL = 64 # 인코더와 디코더 내부의 입/출력의 고정 차원\n",
    "# UNITS = 128 # 피드 포워드 신경망의 은닉층의 크기\n",
    "# DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "NUM_HEADS = 4 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "NUM_CLASSES = len(class_label)  #레이블 수\n",
    "VOCAB_SIZE = tokenizer.vocab_size #단어사전 크기\n",
    "MAX_LENGTH = X.shape[1] # maxlen\n",
    "\n",
    "# model = transformer(\n",
    "#             vocab_size=VOCAB_SIZE,\n",
    "#             num_layers=NUM_LAYERS,\n",
    "#             units=UNITS,\n",
    "#             d_model=D_MODEL,\n",
    "#             num_heads=NUM_HEADS,\n",
    "#             num_classes=NUM_CLASSES,\n",
    "#             dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe56a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"sweep_test_nlp\",\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"method\": \"random\",\n",
    "    \"parameters\": {\n",
    "        \"UNITS\" : {\"values\" : [32, 64, 128]},\n",
    "        \"NUM_LAYERS\" : {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"min\" : 3,\n",
    "            \"max\" : 6\n",
    "        },\n",
    "        \"D_MODEL\" :{\"values\" : [32, 64, 128]}            \n",
    "                    \n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b4a1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    default_config = {\n",
    "        \"VOCAB_SIZE\" : VOCAB_SIZE,\n",
    "        \"UNITS\" : 128,\n",
    "        \"NUM_CLASSES\" : 5,\n",
    "        \"loss\" : \"sparse_categorical_crossentropy\",\n",
    "        \"metrics\" : [\"accuracy\"],\n",
    "        \"epoch\" : 30,\n",
    "        \"batch_size\" : 32,\n",
    "        \"NUM_LAYERS\" : 4,\n",
    "        \"D_MODEL\" : 128,\n",
    "        \"NUM_HEADS\" : 4  \n",
    "    }\n",
    "    import os\n",
    "\n",
    "    # 환경 변수 설정\n",
    "    os.environ['WANDB_AGENT_DISABLE_FLAPPING'] = 'true'\n",
    "\n",
    "    wandb.init(config = default_config)\n",
    "    \n",
    "    config = wandb.config\n",
    "    \n",
    "    model = transformer(\n",
    "        vocab_size=config.VOCAB_SIZE,\n",
    "        num_layers=config.NUM_LAYERS,\n",
    "        units=config.UNITS,\n",
    "        d_model=config.D_MODEL,\n",
    "        num_heads=config.NUM_HEADS,\n",
    "        num_classes=config.NUM_CLASSES,\n",
    "        dropout=0.1)\n",
    "\n",
    "    # 머신 러닝 학습때 여러가지 optimzier를 사용할 경우나 learning rate를 조절할 경우에는 아래와 같은 형태의 코드를 응용합니다.\n",
    "\n",
    "    # Optimizer 설정 \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "                                                       \n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = config.loss,\n",
    "                  metrics = config.metrics)\n",
    "\n",
    "    # WandbCallback 함수는 후술합니다.    \n",
    "    EarlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "    from wandb.keras import WandbCallback\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              epochs = config.epoch,\n",
    "              batch_size = config.batch_size,\n",
    "              validation_split=0.2,\n",
    "              callbacks = [EarlyStopping, WandbCallback()])\n",
    "    \n",
    "    \n",
    "    validation_loss, validation_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "    \n",
    "    validation_loss_log = validation_loss.numpy() if isinstance(validation_loss, tf.Tensor) else validation_loss\n",
    "    validation_accuracy_log = validation_accuracy.numpy() if isinstance(validation_accuracy, tf.Tensor) else validation_accuracy\n",
    "  \n",
    "\n",
    "    \n",
    "    # wandb.log 함수 안에 기록하고 싶은 정보를 담습니다.\n",
    "    \n",
    "    wandb.log({\"Validation Accuracy Rate: \" : round(validation_accuracy_log * 100, 2),\n",
    "               \"Validation Error Rate: \" : round((1 - validation_accuracy_log) * 100, 2),\n",
    "               \"Validation Loss\" : validation_loss_log\n",
    "              })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917dd3e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ullwpbz5\n",
      "Sweep URL: https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 99nu7qay with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_MODEL: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tNUM_LAYERS: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUNITS: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msilpiria98\u001b[0m (\u001b[33msilpiria\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/silpiria/DLTHON1/runs/99nu7qay' target=\"_blank\">glad-sweep-1</a></strong> to <a href='https://wandb.ai/silpiria/DLTHON1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/silpiria/DLTHON1' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/silpiria/DLTHON1/runs/99nu7qay' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1/runs/99nu7qay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "223/223 [==============================] - 17s 48ms/step - loss: 1.2972 - accuracy: 0.4162 - val_loss: 1.2273 - val_accuracy: 0.4287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 1.1731 - accuracy: 0.4797 - val_loss: 1.1252 - val_accuracy: 0.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 1.0405 - accuracy: 0.5664 - val_loss: 0.9294 - val_accuracy: 0.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.8466 - accuracy: 0.6647 - val_loss: 0.8037 - val_accuracy: 0.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.7362 - accuracy: 0.7135 - val_loss: 0.7988 - val_accuracy: 0.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.6608 - accuracy: 0.7457 - val_loss: 0.6842 - val_accuracy: 0.7402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.5982 - accuracy: 0.7712 - val_loss: 0.6845 - val_accuracy: 0.7464\n",
      "Epoch 8/30\n",
      "223/223 [==============================] - 10s 43ms/step - loss: 0.5558 - accuracy: 0.7912 - val_loss: 0.6689 - val_accuracy: 0.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.5157 - accuracy: 0.8103 - val_loss: 0.6422 - val_accuracy: 0.7626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.4913 - accuracy: 0.8159 - val_loss: 0.5901 - val_accuracy: 0.7772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.4736 - accuracy: 0.8251 - val_loss: 0.5805 - val_accuracy: 0.7811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_115641-99nu7qay/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.4340 - accuracy: 0.8392 - val_loss: 0.6889 - val_accuracy: 0.7379\n",
      "Epoch 13/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.4137 - accuracy: 0.8479 - val_loss: 0.6001 - val_accuracy: 0.7744\n",
      "Epoch 14/30\n",
      "223/223 [==============================] - 9s 42ms/step - loss: 0.3947 - accuracy: 0.8544 - val_loss: 0.6155 - val_accuracy: 0.7727\n",
      "31/31 - 1s - loss: 0.6164 - accuracy: 0.7838\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='278.486 MB of 278.487 MB uploaded (2.110 MB deduped)\\r'), FloatProgress(value=0.99…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation Accuracy Rate: </td><td>▁</td></tr><tr><td>Validation Error Rate: </td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr><tr><td>accuracy</td><td>▁▂▃▅▆▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▇▆▅▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▅▆▆▇▇▇███▇██</td></tr><tr><td>val_loss</td><td>█▇▅▃▃▂▂▂▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation Accuracy Rate: </td><td>78.38</td></tr><tr><td>Validation Error Rate: </td><td>21.62</td></tr><tr><td>Validation Loss</td><td>0.61644</td></tr><tr><td>accuracy</td><td>0.85438</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.58053</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>loss</td><td>0.39466</td></tr><tr><td>val_accuracy</td><td>0.77273</td></tr><tr><td>val_loss</td><td>0.61555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-1</strong> at: <a href='https://wandb.ai/silpiria/DLTHON1/runs/99nu7qay' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1/runs/99nu7qay</a><br/>Synced 5 W&B file(s), 1 media file(s), 40 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240626_115641-99nu7qay/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q6lor9ty with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_MODEL: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tNUM_LAYERS: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUNITS: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/silpiria/DLTHON1/runs/q6lor9ty' target=\"_blank\">autumn-sweep-2</a></strong> to <a href='https://wandb.ai/silpiria/DLTHON1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/silpiria/DLTHON1' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1/sweeps/ullwpbz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/silpiria/DLTHON1/runs/q6lor9ty' target=\"_blank\">https://wandb.ai/silpiria/DLTHON1/runs/q6lor9ty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "223/223 [==============================] - 15s 41ms/step - loss: 1.5045 - accuracy: 0.3309 - val_loss: 1.2872 - val_accuracy: 0.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 1.2325 - accuracy: 0.4314 - val_loss: 1.2243 - val_accuracy: 0.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 1.1748 - accuracy: 0.4652 - val_loss: 1.1400 - val_accuracy: 0.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 1.0932 - accuracy: 0.5147 - val_loss: 1.0327 - val_accuracy: 0.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.9822 - accuracy: 0.5833 - val_loss: 0.8959 - val_accuracy: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.8918 - accuracy: 0.6251 - val_loss: 0.8529 - val_accuracy: 0.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.8253 - accuracy: 0.6528 - val_loss: 0.8076 - val_accuracy: 0.6762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.7750 - accuracy: 0.6871 - val_loss: 0.7502 - val_accuracy: 0.6930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.7276 - accuracy: 0.7069 - val_loss: 0.7535 - val_accuracy: 0.6981\n",
      "Epoch 10/30\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.6925 - accuracy: 0.7247 - val_loss: 0.6860 - val_accuracy: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.6600 - accuracy: 0.7406 - val_loss: 0.6775 - val_accuracy: 0.7363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.6266 - accuracy: 0.7590 - val_loss: 0.6612 - val_accuracy: 0.7486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.6083 - accuracy: 0.7647 - val_loss: 0.6551 - val_accuracy: 0.7508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.5806 - accuracy: 0.7726 - val_loss: 0.6426 - val_accuracy: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.5601 - accuracy: 0.7837 - val_loss: 0.6125 - val_accuracy: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.5498 - accuracy: 0.7870 - val_loss: 0.6385 - val_accuracy: 0.7660\n",
      "Epoch 17/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.5233 - accuracy: 0.8005 - val_loss: 0.5992 - val_accuracy: 0.7840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.4987 - accuracy: 0.8121 - val_loss: 0.5906 - val_accuracy: 0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.4883 - accuracy: 0.8151 - val_loss: 0.5958 - val_accuracy: 0.7806\n",
      "Epoch 20/30\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.4757 - accuracy: 0.8214 - val_loss: 0.6033 - val_accuracy: 0.7778\n",
      "Epoch 21/30\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.4674 - accuracy: 0.8238 - val_loss: 0.5706 - val_accuracy: 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/dktc/wandb/run-20240626_120233-q6lor9ty/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      " 66/223 [=======>......................] - ETA: 5s - loss: 0.4385 - accuracy: 0.8286 ETA: 6s - loss: 0.4180 - accuracy: 0.83 - ETA: 6s"
     ]
    }
   ],
   "source": [
    "# entity와 project에 본인의 아이디와 프로젝트명을 입력하세요\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config,\n",
    "                       entity = 'silpiria',\n",
    "                       project = 'DLTHON1')\n",
    "\n",
    "# run the sweep\n",
    "wandb.agent(sweep_id,\n",
    "            function=train,\n",
    "            count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25731675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b137f69",
   "metadata": {},
   "source": [
    "F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e983c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # 예측값을 0과 1로 반올림\n",
    "    y_pred = tf.round(y_pred)\n",
    "\n",
    "    # True Positives, False Positives, False Negatives 계산\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # Precision, Recall 계산\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    # F1 Score 계산\n",
    "    f1_val = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a60c44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy', f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ec1e80f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 10s 42ms/step - loss: 1.0668 - accuracy: 0.5369 - f1_score: 0.5704 - val_loss: 0.5514 - val_accuracy: 0.8000 - val_f1_score: 0.8798\n",
      "\n",
      "Epoch 00001: saving model to models/4-64-4-128.h5\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 5s 33ms/step - loss: 0.4551 - accuracy: 0.8371 - f1_score: 0.8751 - val_loss: 0.4440 - val_accuracy: 0.8384 - val_f1_score: 0.8988\n",
      "\n",
      "Epoch 00002: saving model to models/4-64-4-128.h5\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 5s 33ms/step - loss: 0.2934 - accuracy: 0.9002 - f1_score: 0.8886 - val_loss: 0.4606 - val_accuracy: 0.8465 - val_f1_score: 0.8967\n",
      "\n",
      "Epoch 00003: saving model to models/4-64-4-128.h5\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 5s 34ms/step - loss: 0.2071 - accuracy: 0.9345 - f1_score: 0.8949 - val_loss: 0.5620 - val_accuracy: 0.8333 - val_f1_score: 0.9005\n",
      "\n",
      "Epoch 00004: saving model to models/4-64-4-128.h5\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 5s 34ms/step - loss: 0.1534 - accuracy: 0.9494 - f1_score: 0.8964 - val_loss: 0.5706 - val_accuracy: 0.8404 - val_f1_score: 0.9031\n",
      "\n",
      "Epoch 00005: saving model to models/4-64-4-128.h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
    "\n",
    "cb = ModelCheckpoint(f'models/{NUM_LAYERS}-{D_MODEL}-{NUM_HEADS}-{UNITS}.h5',\n",
    "                    save_weights_only=True, \n",
    "                    save_best_only=False,    \n",
    "                    monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    verbose=1)\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[EarlyStopping, cb],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b70dc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/4-64-4-128.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2113039",
   "metadata": {},
   "source": [
    "**결과 기록**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5c78568",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('models/transformer_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a06d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/transformer_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef0192b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/transformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1cba37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "599e7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동행렬\n",
    "y_pred = model.predict(X_test,batch_size=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea8b53a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "# 히트맵 그리기\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90118e4c",
   "metadata": {},
   "source": [
    "## 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e69e2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문맥상 진짜 의미가 없는 불용어 제거 \n",
    "stopwords = ['그렇게','아','어떻게', '이렇게', '그렇군요', '있어요']\n",
    "# 워드 클라우드에서 보기 편하게 일반어 제거\n",
    "s = stopwords + ['내가', '다', '니','니가','넌','그냥', '너', '왜', '야','진짜',\n",
    "                '나','좀', '지금', '내', '아니','우리','네','안','그','이','어',\n",
    "                '그래', '그럼', '아니야', '응', '너가', '제가', '저', '거','뭐',\n",
    "                '이거','여기', '저는','저도', '전', '어', '나도', '잘', '너무',\n",
    "                '정말', '나는', '너도', '네가', '넌', '난', '널']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ce8dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sw = data['conversation'].apply(preprocess_sentence, stopwords=s)\n",
    "X_sw_list = list(np.stack(X_sw.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c588627",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_sw = tokenizer(X_sw_list,return_tensors='tf', \n",
    "                   padding=True, truncation=True,max_length=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be9b6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sw = tf.multiply(inputs_sw.input_ids,inputs_sw.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba449e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_sw_train, X_sw_test, y_sw_train, y_sw_test = train_test_split(X_sw.numpy(), y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0d81720e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mr_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__r%s__\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m   1398\u001b[0m       \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmaybe_promote_tensors\u001b[0;34m(force_same_dtype, *tensors)\u001b[0m\n\u001b[1;32m   1334\u001b[0m       promoted_tensors.append(\n\u001b[0;32m-> 1335\u001b[0;31m           ops.convert_to_tensor(tensor, dtype, name=\"x\"))\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpromoted_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;34m'Cannot convert a symbolic Keras input/output to a numpy array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_886/1105003752.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mDROPOUT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;31m# 드롭아웃의 비율\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model = transformer(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_886/1387776923.py\u001b[0m in \u001b[0;36mtransformer\u001b[0;34m(vocab_size, num_layers, units, d_model, num_heads, dropout, num_classes, name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 인코더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     enc_outputs = encoder(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_886/1021501465.py\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(vocab_size, num_layers, units, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 임베딩 레이어\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 포지셔널 인코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(op, args, kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GLOBAL_DISPATCHERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         for x in tf.nest.flatten([args, kwargs])):\n\u001b[0;32m-> 1473\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mTFOpLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    977\u001b[0m                                                 input_list)\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    528\u001b[0m   \"\"\"\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6243\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6244\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6245\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   6246\u001b[0m         \"Mul\", x=x, y=y, name=name)\n\u001b[1;32m   6247\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    621\u001b[0m                 \u001b[0;34m\"Input '%s' of '%s' Op has type %s that does not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;34m\"match type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'."
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_label)\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "MAX_LENGTH = X_sw.shape[1]\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더 층의 개수 \n",
    "D_MODEL = 128 # 인코더 내부의 입/출력의 고정 차원\n",
    "NUM_HEADS = 4 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 256 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd83f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4545/4545 [==============================] - 45s 9ms/step - loss: 1.1662 - accuracy: 0.4931 - f1_score: 0.2532 - val_loss: 0.7803 - val_accuracy: 0.6337 - val_f1_score: 0.5960\n",
      "Epoch 2/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.5793 - accuracy: 0.7780 - f1_score: 0.6814 - val_loss: 0.5257 - val_accuracy: 0.8059 - val_f1_score: 0.7386\n",
      "Epoch 3/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.4021 - accuracy: 0.8475 - f1_score: 0.7509 - val_loss: 0.4951 - val_accuracy: 0.8337 - val_f1_score: 0.7604\n",
      "Epoch 4/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.3137 - accuracy: 0.8865 - f1_score: 0.7760 - val_loss: 0.4582 - val_accuracy: 0.8416 - val_f1_score: 0.7762\n",
      "Epoch 5/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.2454 - accuracy: 0.9140 - f1_score: 0.7872 - val_loss: 0.5471 - val_accuracy: 0.8218 - val_f1_score: 0.7861\n",
      "Epoch 6/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.2021 - accuracy: 0.9256 - f1_score: 0.7921 - val_loss: 0.5124 - val_accuracy: 0.8475 - val_f1_score: 0.8000\n",
      "Epoch 7/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.1583 - accuracy: 0.9454 - f1_score: 0.7969 - val_loss: 0.5266 - val_accuracy: 0.8475 - val_f1_score: 0.8040\n",
      "Epoch 8/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.1207 - accuracy: 0.9600 - f1_score: 0.7998 - val_loss: 0.5236 - val_accuracy: 0.8634 - val_f1_score: 0.8040\n",
      "Epoch 9/10\n",
      "4545/4545 [==============================] - 41s 9ms/step - loss: 0.0962 - accuracy: 0.9694 - f1_score: 0.8009 - val_loss: 0.5840 - val_accuracy: 0.8455 - val_f1_score: 0.8059\n",
      "Epoch 10/10\n",
      "4545/4545 [==============================] - 42s 9ms/step - loss: 0.0847 - accuracy: 0.9734 - f1_score: 0.8024 - val_loss: 0.6752 - val_accuracy: 0.8515 - val_f1_score: 0.8059\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy', f1_score])\n",
    "history = model.fit(X_sw_train,\n",
    "                    y_sw_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=1,\n",
    "                    validation_data=(X_sw_test, y_sw_test),\n",
    "                    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1014bb",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "Epoch 10/10\n",
    "4545/4545 [==============================] - 42s 9ms/step - loss: 0.0847 - accuracy: 0.9734 - f1_score: 0.8024 - val_loss: 0.6752 - val_accuracy: 0.8515 - val_f1_score: 0.8059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77fd59a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 혼동행렬\n",
    "y_sw_pred = model.predict(X_sw_test,batch_size=1)\n",
    "y_sw_pred_classes = np.argmax(y_sw_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(y_sw_test, y_sw_pred_classes)\n",
    "# 히트맵 그리기\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4df6596f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6336633563041687,\n",
       " 0.805940568447113,\n",
       " 0.8336633443832397,\n",
       " 0.8415841460227966,\n",
       " 0.8217821717262268,\n",
       " 0.8475247621536255,\n",
       " 0.8475247621536255,\n",
       " 0.8633663654327393,\n",
       " 0.8455445766448975,\n",
       " 0.8514851331710815]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b3fad",
   "metadata": {},
   "source": [
    "# test submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8a883f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/custom_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0b04f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'선생님도 환자타는 징크스 있겠네요 난 그런거 없어 특이하네요 다들 하나씩 있으시던데 굳이 있다면 족보에도 나와있는 전통적인 징크스 그정도 그게 뭔데요 후배가 산 과자나 음식을 하나라도 먹는다면 어떻게 되는데요 하늘에서 환자가 우수수수수 내려 아 큰일났다 왜왜 내가 지금 먹는 아이스크림 누가 산거야 제 제가 빨리 계좌번호 불러 빨리 돈 보내줄게'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['conversation'][29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a3f7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_sentence(sentence, stopwords=None):\n",
    "    # 개행자 삭제\n",
    "    sentence = re.sub(r'[\\n\\r]', ' ', sentence)\n",
    "    \n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다. \n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z,가-힣,0-9, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣0-9\\.\\?\\!,]\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # '키키'와 같이 연속된 키를 제거합니다.\n",
    "    sentence = re.sub(r'키{2,}', '', sentence)\n",
    "    sentence = re.sub(r'\\b키\\b', '', sentence)\n",
    "\n",
    "    if stopwords:\n",
    "        words = sentence.split()\n",
    "        filtered_words = [word for word in words if word not in stopwords]\n",
    "        sentence = ' '.join(filtered_words)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cccb38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test['conversation'].apply(preprocess_sentence)\n",
    "test_X_list = list(np.stack(test_X.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bb5c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = tokenizer(test_X_list,return_tensors='tf', \n",
    "                   padding=True, truncation=True,max_length=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b8dc72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = tf.multiply(inputs_test.input_ids,inputs_test.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4c32afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_X, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c9d6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('transformer_predictions.npy', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d36d3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf066d",
   "metadata": {},
   "source": [
    "서브미션 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e416332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"data/new_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73cd3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['class']=predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ddb655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('data/sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf0800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb421cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
